{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BEYil2OCpcCI"
      },
      "outputs": [],
      "source": [
        "# Dataset - https://www.kaggle.com/datasets/salader/dogs-vs-cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ltXgmnE_AjI",
        "outputId": "8abaa1b9-d836-43dc-ea2b-ea6a6c93283e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The syntax of the command is incorrect.\n",
            "'cp' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ygyow4lpz7K",
        "outputId": "072ddf4b-945b-4f82-e5e3-1401e82939da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'kaggle' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d shaunthesheep/microsoft-catsvsdogs-dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extraemos las imagenes del acrhivo zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "dRq_DVNNp7T-",
        "outputId": "431c89ec-9333-4fa0-a8fe-8c1af5c22251"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('archive.zip', 'r')\n",
        "zip_ref.extractall('')\n",
        "zip_ref.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ruta a la carpeta PetImages que contiene las carpetas Cat y Dog\n",
        "source_dir = \"PetImages\"\n",
        "\n",
        "# Crear las carpetas Train y Test\n",
        "os.mkdir(os.path.join(source_dir, \"Train\"))\n",
        "os.mkdir(os.path.join(source_dir, \"Test\"))\n",
        "\n",
        "# Crear las carpetas Cat y Dog dentro de Train y Test\n",
        "os.mkdir(os.path.join(source_dir, \"Train\", \"Cat\"))\n",
        "os.mkdir(os.path.join(source_dir, \"Train\", \"Dog\"))\n",
        "os.mkdir(os.path.join(source_dir, \"Test\", \"Cat\"))\n",
        "os.mkdir(os.path.join(source_dir, \"Test\", \"Dog\"))\n",
        "\n",
        "# Dividir las imágenes de gatos en conjuntos de entrenamiento y prueba\n",
        "cat_dir = os.path.join(source_dir, \"Cat\")\n",
        "cat_filenames = os.listdir(cat_dir)\n",
        "cat_train_filenames, cat_test_filenames = train_test_split(cat_filenames, test_size=0.2, random_state=42)\n",
        "\n",
        "# Mover las imágenes de gatos a las carpetas correspondientes en Train y Test\n",
        "for filename in cat_train_filenames:\n",
        "    source = os.path.join(cat_dir, filename)\n",
        "    destination = os.path.join(source_dir, \"Train\", \"Cat\", filename)\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "for filename in cat_test_filenames:\n",
        "    source = os.path.join(cat_dir, filename)\n",
        "    destination = os.path.join(source_dir, \"Test\", \"Cat\", filename)\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "# Dividir las imágenes de perros en conjuntos de entrenamiento y prueba\n",
        "dog_dir = os.path.join(source_dir, \"Dog\")\n",
        "dog_filenames = os.listdir(dog_dir)\n",
        "dog_train_filenames, dog_test_filenames = train_test_split(dog_filenames, test_size=0.2, random_state=42)\n",
        "\n",
        "# Mover las imágenes de perros a las carpetas correspondientes en Train y Test\n",
        "for filename in dog_train_filenames:\n",
        "    source = os.path.join(dog_dir, filename)\n",
        "    destination = os.path.join(source_dir, \"Train\", \"Dog\", filename)\n",
        "    shutil.move(source, destination)\n",
        "\n",
        "for filename in dog_test_filenames:\n",
        "    source = os.path.join(dog_dir, filename)\n",
        "    destination = os.path.join(source_dir, \"Test\", \"Dog\", filename)\n",
        "    shutil.move(source, destination)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de imágenes en la carpeta de entrenamiento de gatos: 10000\n",
            "Cantidad de imágenes en la carpeta de entrenamiento de perros: 10000\n",
            "Cantidad de imágenes en la carpeta de prueba de gatos: 2501\n",
            "Cantidad de imágenes en la carpeta de prueba de perros: 2501\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "train_dir = \"Train\"\n",
        "test_dir = \"Test\"\n",
        "\n",
        "cat_train_dir = os.path.join('PetImages', train_dir, \"Cat\")\n",
        "dog_train_dir = os.path.join('PetImages', train_dir, \"Dog\")\n",
        "cat_test_dir = os.path.join('PetImages', test_dir, \"Cat\")\n",
        "dog_test_dir = os.path.join('PetImages', test_dir, \"Dog\")\n",
        "\n",
        "print(\"Cantidad de imágenes en la carpeta de entrenamiento de gatos:\", len(os.listdir(cat_train_dir)))\n",
        "print(\"Cantidad de imágenes en la carpeta de entrenamiento de perros:\", len(os.listdir(dog_train_dir)))\n",
        "print(\"Cantidad de imágenes en la carpeta de prueba de gatos:\", len(os.listdir(cat_test_dir)))\n",
        "print(\"Cantidad de imágenes en la carpeta de prueba de perros:\", len(os.listdir(dog_test_dir)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HLjhKoPuqLL1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-f2dkRxXqobD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# generators\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = 'PetImages/Train',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = 'PetImages/Test',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2H94lUTyr_Rd"
      },
      "outputs": [],
      "source": [
        "# Normalize\n",
        "def process(image,label):\n",
        "    image = tf.cast(image/255. ,tf.float32)\n",
        "    return image,label\n",
        "\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_FcGcmkescVi"
      },
      "outputs": [],
      "source": [
        "# create CNN model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7aJZyq2Ltdno"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 254, 254, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 125, 125, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 60, 60, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 115200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               14745728  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,848,193\n",
            "Trainable params: 14,847,745\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SL-E5k_5tf9N"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HHBFNFHCtzLu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 86/625 [===>..........................] - ETA: 13:41 - loss: 4.0813 - accuracy: 0.5509"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nInput is empty.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2691]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds,epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49mvalidation_ds)\n",
            "File \u001b[1;32mc:\\Users\\Cristian Aguirre\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Cristian Aguirre\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nInput is empty.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_2691]"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds,epochs=1,validation_data=validation_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLXWhpapuAuV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'],color='red',label='train')\n",
        "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSm7TIfO7Ve0"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'],color='red',label='train')\n",
        "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgG1voHM2rlf"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvbfHPut7Zer"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'],color='red',label='train')\n",
        "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NgMfTQk2-bj"
      },
      "outputs": [],
      "source": [
        "# ways to reduce overfitting\n",
        "\n",
        "# Add more data\n",
        "# Data Augmentation -> next video\n",
        "# L1/L2 Regularizer\n",
        "# Dropout\n",
        "# Batch Norm\n",
        "# Reduce complexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4qNNsN28GTc"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU3N6vPQ8z_t"
      },
      "outputs": [],
      "source": [
        "test_img = cv2.imread('/content/cat.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsiIWUQO88TH"
      },
      "outputs": [],
      "source": [
        "plt.imshow(test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-IOidqx8_wv"
      },
      "outputs": [],
      "source": [
        "test_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbhZpyb29OPB"
      },
      "outputs": [],
      "source": [
        "test_img = cv2.resize(test_img,(256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1LvBs8J9Qlc"
      },
      "outputs": [],
      "source": [
        "test_input = test_img.reshape((1,256,256,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syGMbjmU9grR"
      },
      "outputs": [],
      "source": [
        "model.predict(test_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRkIkniZ9mOI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
